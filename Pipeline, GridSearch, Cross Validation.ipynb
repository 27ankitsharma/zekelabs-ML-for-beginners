{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC - support vector classifier. This acts as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA - acts as a transormer for minimizing features\n",
    "* from 1000 features, it can find 100 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elements = [('reduce_dim',PCA()), ('clf',SVC())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98666666666666669"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(iris.data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX, trainY, testY =  train_test_split(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94736842105263153"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipe, iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98000000000000009"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(preprocessing.StandardScaler(), SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95383986928104569"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(pipe, iris.data, iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch for Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LinearRegression in module sklearn.linear_model.base:\n",
      "\n",
      "class LinearRegression(LinearModel, sklearn.base.RegressorMixin)\n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : boolean, optional, default True\n",
      " |      whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (e.g. data is expected to be already centered).\n",
      " |  \n",
      " |  normalize : boolean, optional, default False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit`` on\n",
      " |      an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : boolean, optional, default True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int, optional, default 1\n",
      " |      The number of jobs to use for the computation.\n",
      " |      If -1 all CPUs are used. This will only provide speedup for\n",
      " |      n_targets > 1 and sufficient large problems.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  intercept_ : array\n",
      " |      Independent term in the linear model.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      LinearModel\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array or sparse matrix of shape [n_samples,n_features]\n",
      " |          Training data\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples, n_targets]\n",
      " |          Target values. Will be cast to X's dtype if necessary\n",
      " |      \n",
      " |      sample_weight : numpy array of shape [n_samples]\n",
      " |          Individual weights for each sample\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x188c93cb278>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(digits.data[5].reshape((8,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEruQnAHP/g0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x188c71cf6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X,y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf','linear'], \n",
    "                     'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    \n",
    "                    {'kernel': ['linear'], \n",
    "                     'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf', 'linear']}, {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 2, 6, 6, 7, 1, 9, 8, 5, 2, 8, 6, 6, 6, 6, 1, 0, 5, 8, 8, 7, 8,\n",
       "       4, 7, 5, 4, 9, 2, 9, 4, 7, 6, 8, 9, 4, 3, 1, 0, 1, 8, 6, 7, 7, 1, 0,\n",
       "       7, 6, 2, 1, 9, 6, 7, 9, 0, 0, 5, 1, 6, 3, 0, 2, 3, 4, 1, 9, 7, 6, 9,\n",
       "       1, 8, 3, 5, 1, 2, 8, 2, 2, 9, 7, 2, 3, 6, 0, 5, 3, 7, 5, 1, 2, 9, 9,\n",
       "       3, 1, 7, 7, 4, 8, 5, 8, 5, 5, 2, 5, 9, 0, 7, 1, 4, 7, 3, 4, 8, 9, 7,\n",
       "       9, 8, 2, 6, 5, 2, 5, 8, 4, 1, 7, 0, 6, 1, 5, 9, 9, 9, 5, 9, 9, 5, 7,\n",
       "       5, 6, 2, 8, 6, 9, 6, 1, 5, 1, 5, 9, 9, 1, 5, 3, 6, 1, 8, 9, 8, 7, 6,\n",
       "       7, 6, 5, 6, 0, 8, 8, 9, 8, 6, 1, 0, 4, 1, 6, 3, 8, 6, 7, 4, 9, 6, 3,\n",
       "       0, 3, 3, 3, 0, 7, 7, 5, 7, 8, 0, 7, 8, 9, 6, 4, 5, 0, 1, 4, 6, 4, 3,\n",
       "       3, 0, 9, 5, 9, 2, 1, 4, 2, 1, 6, 8, 9, 2, 4, 9, 3, 7, 6, 2, 3, 3, 1,\n",
       "       6, 9, 3, 6, 3, 2, 2, 0, 7, 6, 1, 1, 9, 7, 2, 7, 8, 5, 5, 7, 5, 2, 3,\n",
       "       7, 2, 7, 5, 5, 7, 0, 9, 1, 6, 5, 9, 7, 4, 3, 8, 0, 3, 6, 4, 6, 3, 2,\n",
       "       6, 8, 8, 8, 4, 6, 7, 5, 2, 4, 5, 3, 2, 4, 6, 9, 4, 5, 4, 3, 4, 6, 2,\n",
       "       9, 0, 1, 7, 2, 0, 9, 6, 0, 4, 2, 0, 7, 9, 8, 5, 4, 8, 2, 8, 4, 3, 7,\n",
       "       2, 6, 9, 1, 5, 1, 0, 8, 2, 1, 9, 5, 6, 8, 2, 7, 2, 1, 5, 1, 6, 4, 5,\n",
       "       0, 9, 4, 1, 1, 7, 0, 8, 9, 0, 5, 4, 3, 8, 8, 6, 5, 3, 4, 4, 4, 8, 8,\n",
       "       7, 0, 9, 6, 3, 5, 2, 3, 0, 8, 2, 3, 1, 3, 3, 0, 0, 4, 6, 0, 7, 7, 6,\n",
       "       2, 0, 4, 4, 2, 3, 7, 8, 9, 8, 6, 8, 5, 6, 2, 2, 3, 1, 7, 7, 8, 0, 3,\n",
       "       3, 2, 1, 5, 5, 9, 1, 3, 7, 0, 0, 7, 0, 4, 5, 9, 3, 3, 4, 3, 1, 8, 9,\n",
       "       8, 3, 6, 2, 1, 6, 2, 1, 7, 5, 5, 1, 9, 2, 8, 9, 7, 2, 1, 4, 9, 3, 2,\n",
       "       6, 2, 5, 9, 6, 5, 8, 2, 0, 7, 8, 0, 6, 8, 4, 1, 8, 6, 4, 3, 4, 2, 0,\n",
       "       4, 5, 8, 3, 9, 1, 8, 3, 4, 5, 0, 8, 5, 6, 3, 0, 6, 9, 1, 5, 1, 2, 1,\n",
       "       9, 8, 4, 3, 3, 0, 7, 8, 8, 1, 1, 3, 5, 5, 8, 4, 9, 7, 8, 4, 4, 9, 0,\n",
       "       1, 6, 9, 3, 6, 1, 7, 0, 6, 2, 9, 9, 3, 6, 1, 5, 1, 8, 9, 1, 4, 1, 7,\n",
       "       2, 8, 0, 6, 2, 1, 0, 6, 1, 6, 5, 2, 8, 6, 2, 1, 4, 6, 8, 2, 2, 7, 5,\n",
       "       9, 1, 9, 5, 0, 2, 5, 5, 6, 8, 9, 5, 7, 0, 5, 2, 1, 1, 2, 8, 8, 2, 1,\n",
       "       5, 5, 2, 7, 1, 4, 4, 1, 3, 5, 6, 7, 4, 6, 7, 3, 5, 7, 1, 5, 5, 3, 8,\n",
       "       5, 2, 3, 5, 4, 4, 6, 5, 1, 4, 1, 8, 3, 3, 1, 4, 8, 9, 2, 9, 4, 9, 4,\n",
       "       8, 0, 3, 3, 2, 0, 6, 6, 8, 6, 5, 9, 0, 3, 2, 5, 6, 9, 5, 4, 3, 3, 9,\n",
       "       9, 2, 7, 9, 9, 1, 1, 5, 9, 1, 0, 4, 1, 7, 4, 3, 8, 6, 5, 5, 5, 3, 5,\n",
       "       0, 0, 5, 0, 0, 3, 5, 2, 3, 4, 6, 5, 8, 5, 0, 9, 9, 1, 5, 0, 5, 0, 8,\n",
       "       7, 7, 5, 2, 7, 8, 6, 5, 3, 0, 2, 9, 7, 7, 4, 0, 0, 6, 1, 1, 3, 4, 1,\n",
       "       8, 7, 5, 1, 0, 8, 0, 9, 0, 9, 3, 0, 0, 6, 4, 5, 3, 8, 0, 9, 0, 3, 2,\n",
       "       0, 4, 0, 3, 3, 2, 2, 0, 5, 3, 2, 3, 6, 5, 0, 4, 2, 7, 9, 1, 5, 8, 2,\n",
       "       1, 2, 2, 6, 0, 1, 1, 3, 6, 2, 3, 7, 3, 8, 3, 8, 0, 3, 5, 5, 8, 5, 1,\n",
       "       3, 1, 1, 0, 1, 2, 5, 0, 0, 4, 8, 0, 5, 7, 9, 5, 0, 2, 5, 2, 7, 3, 6,\n",
       "       8, 7, 5, 5, 0, 0, 7, 0, 9, 3, 6, 2, 9, 1, 1, 9, 1, 6, 8, 3, 3, 2, 4,\n",
       "       4, 8, 9, 6, 6, 6, 8, 9, 2, 4, 5, 0, 0, 7, 7, 4, 4, 7, 3, 1, 1, 9, 7,\n",
       "       0, 4, 9, 2, 9, 3, 5, 3, 6, 3, 8, 2, 0, 0, 2, 4, 9, 8, 5, 2, 2, 9, 5,\n",
       "       9, 5])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 2, 6, 6, 7, 1, 9, 8, 5, 2, 8, 6, 6, 6, 6, 1, 0, 5, 8, 8, 7, 8,\n",
       "       4, 7, 5, 4, 9, 2, 9, 4, 7, 6, 8, 9, 4, 3, 1, 0, 1, 8, 6, 7, 7, 1, 0,\n",
       "       7, 6, 2, 1, 9, 6, 7, 9, 0, 0, 5, 1, 6, 3, 0, 2, 3, 4, 1, 9, 2, 6, 9,\n",
       "       1, 8, 3, 5, 1, 2, 8, 2, 2, 9, 7, 2, 3, 6, 0, 5, 3, 7, 5, 1, 2, 9, 9,\n",
       "       3, 1, 7, 7, 4, 8, 5, 8, 5, 5, 2, 5, 9, 0, 7, 1, 4, 7, 3, 4, 8, 9, 7,\n",
       "       9, 8, 2, 6, 5, 2, 5, 8, 4, 8, 7, 0, 6, 1, 5, 9, 9, 9, 5, 9, 9, 5, 7,\n",
       "       5, 6, 2, 8, 6, 9, 6, 1, 5, 1, 5, 9, 9, 1, 5, 3, 6, 1, 8, 9, 8, 7, 6,\n",
       "       7, 6, 5, 6, 0, 8, 8, 9, 8, 6, 1, 0, 4, 1, 6, 3, 8, 6, 7, 4, 5, 6, 3,\n",
       "       0, 3, 3, 3, 0, 7, 7, 5, 7, 8, 0, 7, 8, 9, 6, 4, 5, 0, 1, 4, 6, 4, 3,\n",
       "       3, 0, 9, 5, 9, 2, 1, 4, 2, 1, 6, 8, 9, 2, 4, 9, 3, 7, 6, 2, 3, 3, 1,\n",
       "       6, 9, 3, 6, 3, 2, 2, 0, 7, 6, 1, 1, 9, 7, 2, 7, 8, 5, 5, 7, 5, 2, 3,\n",
       "       7, 2, 7, 5, 5, 7, 0, 9, 1, 6, 5, 9, 7, 4, 3, 8, 0, 3, 6, 4, 6, 3, 2,\n",
       "       6, 8, 8, 8, 4, 6, 7, 5, 2, 4, 5, 3, 2, 4, 6, 9, 4, 5, 4, 3, 4, 6, 2,\n",
       "       9, 0, 1, 7, 2, 0, 9, 6, 0, 4, 2, 0, 7, 9, 8, 5, 4, 8, 2, 8, 4, 3, 7,\n",
       "       2, 6, 9, 1, 5, 1, 0, 8, 2, 1, 9, 5, 6, 8, 2, 7, 2, 1, 5, 1, 6, 4, 5,\n",
       "       0, 9, 4, 1, 1, 7, 0, 8, 9, 0, 5, 4, 3, 8, 8, 6, 5, 3, 4, 4, 4, 8, 8,\n",
       "       7, 0, 9, 6, 3, 5, 2, 3, 0, 8, 3, 3, 1, 3, 3, 0, 0, 4, 6, 0, 7, 7, 6,\n",
       "       2, 0, 4, 4, 2, 3, 7, 8, 9, 8, 6, 8, 5, 6, 2, 2, 3, 1, 7, 7, 8, 0, 3,\n",
       "       3, 2, 1, 5, 5, 9, 1, 3, 7, 0, 0, 7, 0, 4, 5, 9, 3, 3, 4, 3, 1, 8, 9,\n",
       "       8, 3, 6, 2, 1, 6, 2, 1, 7, 5, 5, 1, 9, 2, 8, 9, 7, 2, 1, 4, 9, 3, 2,\n",
       "       6, 2, 5, 9, 6, 5, 8, 2, 0, 7, 8, 0, 5, 8, 4, 1, 8, 6, 4, 3, 4, 2, 0,\n",
       "       4, 5, 8, 3, 9, 1, 8, 3, 4, 5, 0, 8, 5, 6, 3, 0, 6, 9, 1, 5, 2, 2, 1,\n",
       "       9, 8, 4, 3, 3, 0, 7, 8, 8, 1, 1, 3, 5, 5, 8, 4, 9, 7, 8, 4, 4, 9, 0,\n",
       "       1, 6, 9, 3, 6, 1, 7, 0, 6, 2, 9, 9, 3, 6, 1, 5, 1, 8, 9, 8, 4, 1, 7,\n",
       "       2, 8, 0, 6, 2, 1, 0, 6, 1, 6, 5, 2, 8, 6, 2, 1, 4, 6, 8, 2, 2, 7, 5,\n",
       "       9, 1, 9, 5, 0, 2, 5, 5, 6, 8, 9, 5, 7, 0, 5, 2, 1, 1, 2, 8, 8, 2, 1,\n",
       "       5, 5, 2, 7, 1, 4, 4, 1, 3, 5, 6, 7, 4, 6, 7, 3, 5, 7, 1, 5, 5, 3, 8,\n",
       "       5, 2, 3, 5, 4, 4, 6, 5, 1, 4, 1, 8, 3, 3, 1, 4, 8, 9, 2, 9, 4, 9, 4,\n",
       "       8, 0, 3, 3, 2, 0, 6, 6, 8, 6, 5, 9, 0, 3, 2, 5, 6, 9, 5, 4, 3, 3, 9,\n",
       "       9, 2, 7, 9, 9, 1, 1, 5, 9, 1, 0, 4, 1, 7, 4, 3, 8, 6, 5, 5, 5, 3, 5,\n",
       "       0, 0, 5, 0, 0, 3, 5, 2, 3, 4, 6, 5, 8, 5, 0, 9, 9, 1, 5, 0, 5, 0, 8,\n",
       "       7, 7, 5, 2, 7, 8, 6, 5, 3, 0, 2, 9, 7, 7, 4, 0, 0, 6, 1, 1, 3, 4, 1,\n",
       "       8, 7, 5, 1, 0, 8, 0, 9, 0, 9, 3, 0, 0, 6, 4, 5, 3, 8, 0, 9, 0, 3, 2,\n",
       "       0, 4, 0, 3, 3, 2, 2, 0, 5, 3, 2, 3, 6, 5, 0, 4, 2, 7, 9, 1, 5, 8, 2,\n",
       "       1, 2, 2, 6, 0, 1, 1, 3, 6, 2, 3, 7, 3, 8, 3, 8, 0, 3, 5, 5, 8, 5, 1,\n",
       "       3, 1, 1, 0, 1, 2, 5, 0, 0, 4, 8, 0, 5, 7, 9, 5, 0, 2, 5, 2, 7, 3, 6,\n",
       "       8, 7, 9, 5, 0, 0, 7, 0, 9, 3, 6, 2, 9, 1, 1, 9, 1, 6, 8, 3, 3, 2, 4,\n",
       "       4, 8, 9, 6, 6, 6, 8, 9, 2, 4, 5, 0, 0, 7, 7, 4, 4, 7, 3, 1, 1, 9, 7,\n",
       "       0, 4, 9, 2, 9, 3, 5, 3, 6, 3, 8, 2, 0, 0, 2, 4, 9, 8, 5, 2, 2, 9, 5,\n",
       "       9, 5])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99110122358175756"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.12183847,  0.04160838,  0.07900019,  0.04090896,  0.09409556,\n",
       "         0.04059858,  0.05514975,  0.04090414,  0.09209237,  0.04158688,\n",
       "         0.04858685,  0.04121509,  0.09350715,  0.04123173,  0.04714541,\n",
       "         0.0456284 ,  0.04002342,  0.0414175 ,  0.0394073 ,  0.04068279]),\n",
       " 'mean_score_time': array([ 0.02035737,  0.01181302,  0.020789  ,  0.01186185,  0.01731696,\n",
       "         0.01044512,  0.01371469,  0.01071248,  0.01789575,  0.01079159,\n",
       "         0.01298523,  0.01073174,  0.01763115,  0.01098194,  0.01272969,\n",
       "         0.01464043,  0.01099796,  0.01072917,  0.01080194,  0.01093106]),\n",
       " 'mean_test_score': array([ 0.98552339,  0.97327394,  0.95768374,  0.97327394,  0.98663697,\n",
       "         0.97327394,  0.98106904,  0.97327394,  0.98663697,  0.97327394,\n",
       "         0.98106904,  0.97327394,  0.98663697,  0.97327394,  0.98106904,\n",
       "         0.97327394,  0.97327394,  0.97327394,  0.97327394,  0.97327394]),\n",
       " 'mean_train_score': array([ 0.99888733,  1.        ,  0.96769652,  1.        ,  1.        ,\n",
       "         1.        ,  0.99805051,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'param_C': masked_array(data = [1 1 1 1 10 10 10 10 100 100 100 100 1000 1000 1000 1000 1 10 100 1000],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_gamma': masked_array(data = [0.001 0.001 0.0001 0.0001 0.001 0.001 0.0001 0.0001 0.001 0.001 0.0001\n",
       "  0.0001 0.001 0.001 0.0001 0.0001 -- -- -- --],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False  True  True  True  True],\n",
       "        fill_value = ?),\n",
       " 'param_kernel': masked_array(data = ['rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear'\n",
       "  'rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear' 'linear' 'linear' 'linear'\n",
       "  'linear'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 100, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'kernel': 'linear'}],\n",
       " 'rank_test_score': array([ 4,  8, 20,  8,  1,  8,  5,  8,  1,  8,  5,  8,  1,  8,  5,  8,  8,\n",
       "         8,  8,  8]),\n",
       " 'split0_test_score': array([ 0.99453552,  0.9726776 ,  0.97814208,  0.9726776 ,  0.99453552,\n",
       "         0.9726776 ,  0.99453552,  0.9726776 ,  0.99453552,  0.9726776 ,\n",
       "         0.98907104,  0.9726776 ,  0.99453552,  0.9726776 ,  0.98907104,\n",
       "         0.9726776 ,  0.9726776 ,  0.9726776 ,  0.9726776 ,  0.9726776 ]),\n",
       " 'split0_train_score': array([ 0.9986014 ,  1.        ,  0.96503497,  1.        ,  1.        ,\n",
       "         1.        ,  0.9986014 ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split1_test_score': array([ 0.98901099,  0.97802198,  0.96153846,  0.97802198,  0.98901099,\n",
       "         0.97802198,  0.97802198,  0.97802198,  0.98901099,  0.97802198,\n",
       "         0.98351648,  0.97802198,  0.98901099,  0.97802198,  0.98351648,\n",
       "         0.97802198,  0.97802198,  0.97802198,  0.97802198,  0.97802198]),\n",
       " 'split1_train_score': array([ 1.        ,  1.        ,  0.96368715,  1.        ,  1.        ,\n",
       "         1.        ,  0.9972067 ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split2_test_score': array([ 0.96648045,  0.96089385,  0.94413408,  0.96089385,  0.96648045,\n",
       "         0.96089385,  0.96089385,  0.96089385,  0.96648045,  0.96089385,\n",
       "         0.95530726,  0.96089385,  0.96648045,  0.96089385,  0.95530726,\n",
       "         0.96089385,  0.96089385,  0.96089385,  0.96089385,  0.96089385]),\n",
       " 'split2_train_score': array([ 0.99860918,  1.        ,  0.96383866,  1.        ,  1.        ,\n",
       "         1.        ,  0.99721836,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split3_test_score': array([ 0.98314607,  0.97191011,  0.93820225,  0.97191011,  0.98876404,\n",
       "         0.97191011,  0.97191011,  0.97191011,  0.98876404,  0.97191011,\n",
       "         0.98314607,  0.97191011,  0.98876404,  0.97191011,  0.98314607,\n",
       "         0.97191011,  0.97191011,  0.97191011,  0.97191011,  0.97191011]),\n",
       " 'split3_train_score': array([ 0.99861111,  1.        ,  0.97777778,  1.        ,  1.        ,\n",
       "         1.        ,  0.99861111,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'split4_test_score': array([ 0.99431818,  0.98295455,  0.96590909,  0.98295455,  0.99431818,\n",
       "         0.98295455,  1.        ,  0.98295455,  0.99431818,  0.98295455,\n",
       "         0.99431818,  0.98295455,  0.99431818,  0.98295455,  0.99431818,\n",
       "         0.98295455,  0.98295455,  0.98295455,  0.98295455,  0.98295455]),\n",
       " 'split4_train_score': array([ 0.99861496,  1.        ,  0.96814404,  1.        ,  1.        ,\n",
       "         1.        ,  0.99861496,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]),\n",
       " 'std_fit_time': array([ 0.04464279,  0.00136475,  0.00135119,  0.00106386,  0.00164637,\n",
       "         0.00136425,  0.01072764,  0.00076767,  0.00121288,  0.00092649,\n",
       "         0.00169511,  0.00086308,  0.00114386,  0.00248045,  0.00137166,\n",
       "         0.01144669,  0.00147064,  0.00197028,  0.00086815,  0.00119724]),\n",
       " 'std_score_time': array([ 0.00390517,  0.00102221,  0.00073599,  0.00213085,  0.00088831,\n",
       "         0.00045523,  0.00074255,  0.00057905,  0.00079726,  0.00037357,\n",
       "         0.00054952,  0.00040214,  0.00099999,  0.00087411,  0.00051385,\n",
       "         0.00627352,  0.00032295,  0.0006792 ,  0.00035539,  0.0007365 ]),\n",
       " 'std_test_score': array([ 0.01037211,  0.00734358,  0.01460789,  0.00734358,  0.01035867,\n",
       "         0.00734358,  0.01438195,  0.00734358,  0.01035867,  0.00734358,\n",
       "         0.01348379,  0.00734358,  0.01035867,  0.00734358,  0.01348379,\n",
       "         0.00734358,  0.00734358,  0.00734358,  0.00734358,  0.00734358]),\n",
       " 'std_train_score': array([ 0.00055635,  0.        ,  0.00528912,  0.        ,  0.        ,\n",
       "         0.        ,  0.00068423,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm.classes:\n",
      "\n",
      "class SVC(sklearn.svm.base.BaseSVC)\n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time complexity\n",
      " |  is more than quadratic with the number of samples which makes it hard\n",
      " |  to scale to dataset with more than a couple of 10000 samples.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, optional (default=1.0)\n",
      " |      Penalty parameter C of the error term.\n",
      " |  \n",
      " |  kernel : string, optional (default='rbf')\n",
      " |       Specifies the kernel type to be used in the algorithm.\n",
      " |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |       a callable.\n",
      " |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |       used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |       should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : float, optional (default='auto')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |      If gamma is 'auto' then 1/n_features will be used instead.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  probability : boolean, optional (default=False)\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, and will slow down that method.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : {dict, 'balanced'}, optional\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2).\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like, shape = [n_SV]\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like, shape = [n_SV, n_features]\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the section about multi-class classification in the\n",
      " |      SVM section of the User Guide for details.\n",
      " |  \n",
      " |  coef_ : array, shape = [n_class-1, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = SVC()\n",
      " |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      " |  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      " |      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      " |      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      " |      tol=0.001, verbose=False)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm.base.BaseSVC\n",
      " |      abc.NewBase\n",
      " |      sklearn.svm.base.BaseLibSVM\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Distance of the samples X to the separating hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes)\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
